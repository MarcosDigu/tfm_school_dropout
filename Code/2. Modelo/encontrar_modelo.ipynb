{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "from itertools import product\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tabulate import tabulate\n",
    "\n",
    "import numpy as np\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos datos depurados\n",
    "df = pd.read_csv('../../Data/dropout_depurado.csv', sep=',')\n",
    "\n",
    "# Separamos features de target\n",
    "y = df['Target_bin']\n",
    "X = df.drop('Target_bin', axis=1)\n",
    "\n",
    "# Separamos train de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a crear un excel de resultados en el que almacenemos los resultados de cada modelo entrenado: la clase, la parametrizacion, la matriz de confusion en 4 columnas (TP, FP, FN, TN), y las variables input del modelo (si en el futuro el pretratamiento cambia, seremos capaces de rastrearlo y comparar distintos pretratamientos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta del archivo\n",
    "file_path = 'tabla_resultados.xlsx'\n",
    "\n",
    "# Comprobar si el archivo existe\n",
    "if os.path.exists(file_path):\n",
    "    # Leer el archivo\n",
    "    operacion_resultados = pd.read_excel(file_path)\n",
    "else:\n",
    "    # Inicializar el DataFrame vacío\n",
    "    operacion_resultados = pd.DataFrame(columns=['Modelo', 'Parametrizacion', 'TP', 'FP', 'FN', 'TN', 'Variables input del modelo', 'Fecha de ejecucion del modelo', 'Comentarios'])\n",
    "\n",
    "models = [\n",
    "    DecisionTreeClassifier(),\n",
    "    LogisticRegression(),\n",
    "    RandomForestClassifier(),\n",
    "    SVC(),\n",
    "    XGBClassifier(),\n",
    "    KNeighborsClassifier(),\n",
    "    GaussianNB(),  # Naive Bayes Classifier\n",
    "    AdaBoostClassifier(),  # AdaBoost Classifier\n",
    "    GradientBoostingClassifier(),  # Gradient Boosting Classifier\n",
    "    MLPClassifier()  # Multi-layer Perceptron Classifier\n",
    "]\n",
    "\n",
    "# Función para mostrar métricas y matriz de confusión\n",
    "def print_evaluation_metrics(model_name, y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    print(f\"Modelo: {model_name}\")\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, \n",
    "                annot_kws={\"size\": 10}, linewidths=0.5, \n",
    "                xticklabels=['No Fraude', 'Fraude'], \n",
    "                yticklabels=['No Fraude', 'Fraude'])\n",
    "    plt.xlabel('Predicción')\n",
    "    plt.ylabel('Verdadero')\n",
    "    plt.title(f'Matriz de Confusión - {model_name}')\n",
    "    plt.show()\n",
    "    \n",
    "    return cm\n",
    "\n",
    "# Entrenar y evaluar cada modelo\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predicciones en el conjunto de prueba\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    cm = print_evaluation_metrics(f'{model_name} (Prueba)', y_test, y_pred_test)\n",
    "    \n",
    "    # Capturando detalles del modelo\n",
    "    params = model.get_params() if hasattr(model, 'get_params') else 'default'\n",
    "    params_json = json.dumps(params)\n",
    "    input_variables = list(X_train.columns)\n",
    "    execution_date = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "    # Extraer TP, FP, FN, TN de la matriz de confusión\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    \n",
    "    # Crear un nuevo DataFrame con los resultados\n",
    "    new_row = pd.DataFrame({\n",
    "        'Modelo': [model_name],\n",
    "        'Comentarios': \"Primera tirada de modelos\",\n",
    "        'TP': [tp],\n",
    "        'FP': [fp],\n",
    "        'FN': [fn],\n",
    "        'TN': [tn],\n",
    "        'Parametrizacion': [params_json],\n",
    "        'Variables input del modelo': [input_variables],\n",
    "        'Fecha de ejecucion del modelo': [execution_date]\n",
    "    })\n",
    "    \n",
    "    # Concatenar el nuevo DataFrame con el DataFrame existente\n",
    "    operacion_resultados = pd.concat([operacion_resultados, new_row], ignore_index=True)\n",
    "\n",
    "    # Guardamos dataframe de resultados actualizados en su sitio\n",
    "    operacion_resultados.to_excel(file_path, index=False)\n",
    "\n",
    "    print(tabulate(new_row, headers='keys', tablefmt='psql'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplo busqueda parametrica para la arquitectura xgboost me come los huevs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier()\n",
    "\n",
    "# Define the expanded parameter grid for XGBClassifier\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.01],\n",
    "    'max_depth': [None, 3],\n",
    "    'min_child_weight': [1, 3],\n",
    "    'subsample': [0.9, 1.0],\n",
    "    'colsample_bytree': [0.9, 1.0],\n",
    "    'gamma': [0, 0.1, 0.2],\n",
    "    'reg_alpha': [0, 0.5, 1],\n",
    "    'reg_lambda': [1, 1.5],\n",
    "    'scale_pos_weight': [1, 2, 5],\n",
    "    'objective': ['binary:logistic', 'binary:hinge', 'binary:logitraw'],\n",
    "    'booster': ['gbtree', 'dart'],\n",
    "    'max_delta_step': [0, 1, 5],\n",
    "    'eval_metric': ['logloss', 'auc']\n",
    "}\n",
    "\n",
    "# Generate all combinations of parameters\n",
    "param_combinations = list(product(*param_grid.values()))\n",
    "\n",
    "# Ruta del archivo\n",
    "file_path = 'tabla_resultados.xlsx'\n",
    "\n",
    "# Comprobar si el archivo existe\n",
    "if os.path.exists(file_path):\n",
    "    # Leer el archivo\n",
    "    operacion_resultados = pd.read_excel(file_path)\n",
    "else:\n",
    "    # Inicializar el DataFrame vacío\n",
    "    operacion_resultados = pd.DataFrame(columns=['Modelo', 'Parametrizacion', 'TP', 'FP', 'FN', 'TN', 'Variables input del modelo', 'Fecha de ejecucion del modelo', 'Comentarios'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import time\n",
    "import cupy as cp\n",
    "\n",
    "# Iniciar el tiempo al inicio del bucle\n",
    "start_time = time.time()\n",
    "\n",
    "# Pedir al usuario que especifique desde qué valor de i comenzar\n",
    "# start_i = int(input(\"Ingrese el valor inicial de i: \")) # Esto es en caso de que se desee detener el entrenamiento y reiniciar desde el mismo punto\n",
    "start_i = 0\n",
    "\n",
    "# Iterar sobre todas las combinaciones de parámetros\n",
    "for i, combination in enumerate(param_combinations[start_i:], start=start_i):\n",
    "    # Crear un diccionario de parámetros para el modelo\n",
    "    params = {key: combination[j] for j, key in enumerate(param_grid.keys())}\n",
    "\n",
    "    print(f'Probando con parametrizacion {i+1}/{len(param_combinations)} con parametros: {params}.')\n",
    "\n",
    "    # Crear y entrenar el modelo con esta configuración\n",
    "    model = XGBClassifier(\n",
    "        n_estimators=params['n_estimators'],\n",
    "        learning_rate=params['learning_rate'],\n",
    "        max_depth=params['max_depth'],\n",
    "        min_child_weight=params['min_child_weight'],\n",
    "        subsample=params['subsample'],\n",
    "        colsample_bytree=params['colsample_bytree'],\n",
    "        gamma=params['gamma'],\n",
    "        reg_alpha=params['reg_alpha'],\n",
    "        reg_lambda=params['reg_lambda'],\n",
    "        scale_pos_weight=params['scale_pos_weight'],\n",
    "        objective=params['objective'],\n",
    "        booster=params['booster'],\n",
    "        max_delta_step=params['max_delta_step'],\n",
    "        tree_method='hist',\n",
    "        device='cuda',\n",
    "        use_label_encoder=False,\n",
    "        eval_metric=params['eval_metric'], \n",
    "        predictor='gpu_predictor'\n",
    "    )\n",
    "\n",
    "    model.fit(np.array(X_train), np.array(y_train))\n",
    "\n",
    "    # Predecir los valores de test\n",
    "    y_pred = model.predict(np.array(X_test))\n",
    "\n",
    "    # Calcular la matriz de confusión\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    print(conf_matrix)\n",
    "    print('\\n' + '-'*40 + '\\n')\n",
    "\n",
    "    # Añadir los valores de la nueva parametrización a la lista de resultados\n",
    "    new_row = {\n",
    "        'Modelo': 'XGBClassifier',\n",
    "        'Parametrizacion': params,\n",
    "        'TP': conf_matrix[1][1],\n",
    "        'FP': conf_matrix[0][1],\n",
    "        'FN': conf_matrix[1][0],\n",
    "        'TN': conf_matrix[0][0],\n",
    "        'Variables input del modelo': list(X_train.columns),\n",
    "        'Fecha de ejecucion del modelo': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        'Comentarios': 'Entrenamiento real XGBoost'\n",
    "    }\n",
    "\n",
    "    # Concatenar el nuevo DataFrame con el DataFrame existente\n",
    "    operacion_resultados = pd.concat([operacion_resultados, pd.DataFrame([new_row])], ignore_index=True)\n",
    "\n",
    "    # Guardar en el archivo Excel cada 100 iteraciones\n",
    "    if (i + 1) % 10 == 0:\n",
    "        operacion_resultados.to_excel(file_path, index=False)\n",
    "        print(f\"Guardado automático en el archivo Excel después de {i + 1} iteraciones.\")\n",
    "\n",
    "# Guardar el DataFrame actualizado en el archivo Excel al finalizar todas las iteraciones\n",
    "operacion_resultados.to_excel(file_path, index=False)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Grid search completed in {end_time - start_time} seconds.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "entorno_tfm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
